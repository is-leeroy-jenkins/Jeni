{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from google.genai.types import GenerateContentConfig, ModelContent, UserContent\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_vertexai import ChatVertexAI, HarmBlockThreshold, HarmCategory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "code_chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=\"You are an expert software engineer, proficient in Python.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "response = code_chat.send_message(\n",
    "    \"Write a function that checks if a year is a leap year\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2 = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    history=[\n",
    "        UserContent(\n",
    "            \"\"\"My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\n",
    "    Who do you work for?\n",
    "    \"\"\"\n",
    "        ),\n",
    "        ModelContent(\"I work for Ned.\"),\n",
    "        UserContent(\"What do I like?\"),\n",
    "        ModelContent(\"Ned likes watching movies.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = chat2.send_message(\"Are my favorite movies based on a book series?\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thinking with Gemini 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"How does AI work?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
    "    contents=\"Hello there\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imagen-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import GenerateImagesConfig\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "# output_file = \"output-image.png\"\n",
    "\n",
    "image = client.models.generate_images(\n",
    "    model=\"imagen-4.0-generate-001\",\n",
    "    prompt=\"A dog reading a newspaper\",\n",
    "    config=GenerateImagesConfig(\n",
    "        image_size=\"2K\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "image.generated_images[0].image.save(output_file)\n",
    "\n",
    "print(f\"Created output image using {len(image.generated_images[0].image.image_bytes)} bytes\")\n",
    "# Example response:\n",
    "# Created output image using 1234567 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nano Banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = (\n",
    "    \"Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme\"\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image\",\n",
    "    contents=[prompt],\n",
    ")\n",
    "\n",
    "for part in response.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image = part.as_image()\n",
    "        image.save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Base image prompt: \"A photorealistic picture of a fluffy ginger cat sitting on a wooden floor, looking directly at the camera. Soft, natural light from a window.\"\n",
    "image_input = Image.open('/path/to/your/cat_photo.png')\n",
    "text_input = \"\"\"Using the provided image of my cat, please add a small, knitted wizard hat on its head. Make it look like it's sitting comfortably and not falling off.\"\"\"\n",
    "\n",
    "# Generate an image from a text prompt\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-image\",\n",
    "    contents=[text_input, image_input],\n",
    ")\n",
    "\n",
    "for part in response.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    elif part.inline_data is not None:\n",
    "        image = part.as_image()\n",
    "        image.save(\"cat_with_hat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "with open('path/to/small-sample.jpg', 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "client = genai.Client()\n",
    "response = client.models.generate_content(\n",
    "model='gemini-2.5-flash',\n",
    "contents=[\n",
    "    types.Part.from_bytes(\n",
    "    data=image_bytes,\n",
    "    mime_type='image/jpeg',\n",
    "    ),\n",
    "    'Caption this image.'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "client = genai.Client()\n",
    "prompt = \"Detect the all of the prominent items in the image. The box_2d should be [ymin, xmin, ymax, xmax] normalized to 0-1000.\"\n",
    "\n",
    "image = Image.open(\"/path/to/image.png\")\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "  response_mime_type=\"application/json\"\n",
    "  )\n",
    "\n",
    "response = client.models.generate_content(model=\"gemini-2.5-flash\",\n",
    "                                          contents=[image, prompt],\n",
    "                                          config=config\n",
    "                                          )\n",
    "\n",
    "width, height = image.size\n",
    "bounding_boxes = json.loads(response.text)\n",
    "\n",
    "converted_bounding_boxes = []\n",
    "for bounding_box in bounding_boxes:\n",
    "    abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "    abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "    abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "    abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "    converted_bounding_boxes.append([abs_x1, abs_y1, abs_x2, abs_y2])\n",
    "\n",
    "print(\"Image size: \", width, height)\n",
    "print(\"Bounding boxes:\", converted_bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "sample_pdf = client.files.upload(file=media / \"test.pdf\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\"Give me a summary of this pdf file.\", sample_pdf],\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "myfile = client.files.upload(file=media / \"poem.txt\")\n",
    "print(f\"{myfile=}\")\n",
    "\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[myfile, \"\\n\\n\", \"Can you add a few more lines to this poem?\"],\n",
    ")\n",
    "print(f\"{result.text=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "myfile = client.files.upload(file=media / \"Cajun_instruments.jpg\")\n",
    "print(f\"{myfile=}\")\n",
    "\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\n",
    "        myfile,\n",
    "        \"\\n\\n\",\n",
    "        \"Can you tell me about the instruments in this photo?\",\n",
    "    ],\n",
    ")\n",
    "print(f\"{result.text=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "myfile = client.files.upload(file=media / \"sample.mp3\")\n",
    "print(f\"{myfile=}\")\n",
    "\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[myfile, \"Describe this audio clip\"]\n",
    ")\n",
    "print(f\"{result.text=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import time\n",
    "\n",
    "client = genai.Client()\n",
    "# Video clip (CC BY 3.0) from https://peach.blender.org/download/\n",
    "myfile = client.files.upload(file=media / \"Big_Buck_Bunny.mp4\")\n",
    "print(f\"{myfile=}\")\n",
    "\n",
    "# Poll until the video file is completely processed (state becomes ACTIVE).\n",
    "while not myfile.state or myfile.state.name != \"ACTIVE\":\n",
    "    print(\"Processing video...\")\n",
    "    print(\"File state:\", myfile.state)\n",
    "    time.sleep(5)\n",
    "    myfile = client.files.get(name=myfile.name)\n",
    "\n",
    "result = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[myfile, \"Describe this video clip\"]\n",
    ")\n",
    "print(f\"{result.text=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "myfile = client.files.upload(file=media / \"poem.txt\")\n",
    "file_name = myfile.name\n",
    "print(file_name)  # \"files/*\"\n",
    "\n",
    "myfile = client.files.get(name=file_name)\n",
    "print(myfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "print(\"My files:\")\n",
    "for f in client.files.list():\n",
    "    print(\"  \", f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "myfile = client.files.upload(file=media / \"poem.txt\")\n",
    "\n",
    "client.files.delete(name=myfile.name)\n",
    "\n",
    "try:\n",
    "    result = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", contents=[myfile, \"Describe this file.\"]\n",
    "    )\n",
    "    print(result)\n",
    "except genai.errors.ClientError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import httpx\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "doc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "doc_data = httpx.get(doc_url).content\n",
    "\n",
    "prompt = \"Summarize this document\"\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[\n",
    "      types.Part.from_bytes(\n",
    "        data=doc_data,\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "filepath = pathlib.Path('file.pdf')\n",
    "\n",
    "prompt = \"Summarize this document\"\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[\n",
    "      types.Part.from_bytes(\n",
    "        data=filepath.read_bytes(),\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "file_path = pathlib.Path('large_file.pdf')\n",
    "\n",
    "# Upload the PDF using the File API\n",
    "sample_file = client.files.upload(\n",
    "  file=file_path,\n",
    ")\n",
    "\n",
    "prompt=\"Summarize this document\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[sample_file, \"Summarize this document\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# File name will be visible in citations\n",
    "file_search_store = client.file_search_stores.create(config={'display_name': 'your-fileSearchStore-name'})\n",
    "\n",
    "operation = client.file_search_stores.upload_to_file_search_store(\n",
    "  file='sample.txt',\n",
    "  file_search_store_name=file_search_store.name,\n",
    "  config={\n",
    "      'display_name' : 'display-file-name',\n",
    "  }\n",
    ")\n",
    "\n",
    "while not operation.done:\n",
    "    time.sleep(5)\n",
    "    operation = client.operations.get(operation)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"\"\"Can you tell me about [insert question]\"\"\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[\n",
    "            types.Tool(\n",
    "                file_search=types.FileSearch(\n",
    "                    file_search_store_names=[file_search_store.name]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# File name will be visible in citations\n",
    "sample_file = client.files.upload(file='sample.txt', config={'name': 'display_file_name'})\n",
    "\n",
    "file_search_store = client.file_search_stores.create(config={'display_name': 'your-fileSearchStore-name'})\n",
    "\n",
    "operation = client.file_search_stores.import_file(\n",
    "    file_search_store_name=file_search_store.name,\n",
    "    file_name=sample_file.name\n",
    ")\n",
    "\n",
    "while not operation.done:\n",
    "    time.sleep(5)\n",
    "    operation = client.operations.get(operation)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"\"\"Can you tell me about [insert question]\"\"\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[\n",
    "            types.Tool(\n",
    "                file_search=types.FileSearch(\n",
    "                    file_search_store_names=[file_search_store.name]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = client.file_search_stores.upload_to_file_search_store(\n",
    "    file_search_store_name=file_search_store.name,\n",
    "    file_name=sample_file.name,\n",
    "    config={\n",
    "        'chunking_config': {\n",
    "          'white_space_config': {\n",
    "            'max_tokens_per_chunk': 200,\n",
    "            'max_overlap_tokens': 20\n",
    "          }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading via Files API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "long_context_pdf_path = \"https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf\"\n",
    "\n",
    "# Retrieve and upload the PDF using the File API\n",
    "doc_io = io.BytesIO(httpx.get(long_context_pdf_path).content)\n",
    "\n",
    "sample_doc = client.files.upload(\n",
    "  # You can pass a path or a file-like object here\n",
    "  file=doc_io,\n",
    "  config=dict(\n",
    "    mime_type='application/pdf')\n",
    ")\n",
    "\n",
    "prompt = \"Summarize this document\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[sample_doc, prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mulitple Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import io\n",
    "import httpx\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "doc_url_1 = \"https://arxiv.org/pdf/2312.11805\"\n",
    "doc_url_2 = \"https://arxiv.org/pdf/2403.05530\"\n",
    "\n",
    "# Retrieve and upload both PDFs using the File API\n",
    "doc_data_1 = io.BytesIO(httpx.get(doc_url_1).content)\n",
    "doc_data_2 = io.BytesIO(httpx.get(doc_url_2).content)\n",
    "\n",
    "sample_pdf_1 = client.files.upload(\n",
    "  file=doc_data_1,\n",
    "  config=dict(mime_type='application/pdf')\n",
    ")\n",
    "sample_pdf_2 = client.files.upload(\n",
    "  file=doc_data_2,\n",
    "  config=dict(mime_type='application/pdf')\n",
    ")\n",
    "\n",
    "prompt = \"What is the difference between each of the main benchmarks between these two papers? Output these in a table.\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[sample_pdf_1, sample_pdf_2, prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate_v3beta1 as translate\n",
    "\n",
    "\n",
    "def translate_document(\n",
    "    project_id: str,\n",
    "    file_path: str,\n",
    ") -> translate.TranslationServiceClient:\n",
    "    \"\"\"Translates a document.\n",
    "\n",
    "    Args:\n",
    "        project_id: The GCP project ID.\n",
    "        file_path: The path to the file to be translated.\n",
    "\n",
    "    Returns:\n",
    "        The translated document.\n",
    "    \"\"\"\n",
    "\n",
    "    client = translate.TranslationServiceClient()\n",
    "    location = \"us-central1\"\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    # Supported file types: https://cloud.google.com/translate/docs/supported-formats\n",
    "    with open(file_path, \"rb\") as document:\n",
    "        document_content = document.read()\n",
    "\n",
    "    document_input_config = {\n",
    "        \"content\": document_content,\n",
    "        \"mime_type\": \"application/pdf\",\n",
    "    }\n",
    "\n",
    "    response = client.translate_document(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"target_language_code\": \"fr-FR\",\n",
    "            \"document_input_config\": document_input_config,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # To output the translated document, uncomment the code below.\n",
    "    # f = open('/tmp/output', 'wb')\n",
    "    # f.write(response.document_translation.byte_stream_outputs[0])\n",
    "    # f.close()\n",
    "\n",
    "    # If not provided in the TranslationRequest, the translated file will only be returned through a byte-stream\n",
    "    # and its output mime type will be the same as the input file's mime type\n",
    "    print(\n",
    "        f\"Response: Detected Language Code - {response.document_translation.detected_language_code}\"\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(  text: str=\"TEXT_TO_TRANSLATE\", source_language_code: str=\"en-US\", target_language_code: str=\"fr\" ) -> translate_v3.TranslationServiceClient:\n",
    "    \"\"\"Translate Text from a Source language to a Target language.\n",
    "    Args:\n",
    "        text: The content to translate.\n",
    "        source_language_code: The code of the source language.\n",
    "        target_language_code: The code of the target language.\n",
    "            For example: \"fr\" for French, \"es\" for Spanish, etc.\n",
    "            Find available languages and codes here:\n",
    "            https://cloud.google.com/translate/docs/languages#neural_machine_translation_model\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Translation client.\n",
    "    client = translate_v3.TranslationServiceClient()\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/global\"\n",
    "\n",
    "    # MIME type of the content to translate.\n",
    "    # Supported MIME types:\n",
    "    # https://cloud.google.com/translate/docs/supported-formats\n",
    "    mime_type = \"text/plain\"\n",
    "\n",
    "    # Translate text from the source to the target language.\n",
    "    response = client.translate_text(\n",
    "        contents=[text],\n",
    "        parent=parent,\n",
    "        mime_type=mime_type,\n",
    "        source_language_code=source_language_code,\n",
    "        target_language_code=target_language_code,\n",
    "    )\n",
    "\n",
    "    # Display the translation for the text.\n",
    "    # For example, for \"Hello! How are you doing today?\":\n",
    "    # Translated text: Bonjour comment vas-tu aujourd'hui?\n",
    "    for translation in response.translations:\n",
    "        print(f\"Translated text: {translation.translated_text}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(  text: str = \"Â¡Hola amigos y amigas!\", target_language: str=\"en\", source_language: str=None, ) -> dict:\n",
    "    \"\"\"\n",
    "    \n",
    "    Translates a given text into the specified target language.\n",
    "\n",
    "    Find a list of supported languages and codes here:\n",
    "    https://cloud.google.com/translate/docs/languages#nmt\n",
    "\n",
    "    Args:\n",
    "        text: The text to translate. Can be a string, bytes or a list of strings.\n",
    "              If bytes, it will be decoded as UTF-8.\n",
    "        target_language: The ISO 639 language code to translate the text into\n",
    "                         (e.g., 'en' for English, 'es' for Spanish).\n",
    "        source_language: Optional. The ISO 639 language code of the input text\n",
    "                         (e.g., 'fr' for French). If None, the API will attempt\n",
    "                         to detect the source language automatically.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the translation results.\n",
    "    \"\"\"\n",
    "\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = [text.decode(\"utf-8\")]\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    # If a string is supplied, a single dictionary will be returned.\n",
    "    # In case a list of strings is supplied, this method\n",
    "    # will return a list of dictionaries.\n",
    "\n",
    "    # Find more information about translate function here:\n",
    "    # https://cloud.google.com/python/docs/reference/translate/latest/google.cloud.translate_v2.client.Client#google_cloud_translate_v2_client_Client_translate\n",
    "    results = translate_client.translate(\n",
    "        values=text,\n",
    "        target_language=target_language,\n",
    "        source_language=source_language\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        if \"detectedSourceLanguage\" in result:\n",
    "            print(f\"Detected source language: {result['detectedSourceLanguage']}\")\n",
    "\n",
    "        print(f\"Input text: {result['input']}\")\n",
    "        print(f\"Translated text: {result['translatedText']}\")\n",
    "        print()\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_file(audio_file: str) -> speech.RecognizeResponse:\n",
    "    \"\"\"\n",
    "    \n",
    "        Purpose:\n",
    "        ----------\n",
    "        Transcribe the given audio file.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        audio_file (str): Path to the local audio file to be transcribed.\n",
    "        Example: \"resources/audio.wav\"\n",
    "                \n",
    "        Returns:\n",
    "        --------\n",
    "        cloud_speech.RecognizeResponse: The response containing the transcription results\n",
    "        \n",
    "    \"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        audio_content = f.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=audio_content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(developer): Update and un-comment below line\n",
    "# PROJECT_ID = \"your-project-id\"\n",
    "\n",
    "# Instantiates a client\n",
    "client = SpeechClient()\n",
    "\n",
    "# Reads a file as bytes\n",
    "with open(\"resources/audio.wav\", \"rb\") as f:\n",
    "    audio_content = f.read()\n",
    "\n",
    "config = cloud_speech.RecognitionConfig(\n",
    "    auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
    "    language_codes=[\"en-US\"],\n",
    "    model=\"chirp_3\",\n",
    ")\n",
    "\n",
    "request = cloud_speech.RecognizeRequest(\n",
    "    recognizer=f\"projects/{PROJECT_ID}/locations/global/recognizers/_\",\n",
    "    config=config,\n",
    "    content=audio_content,\n",
    ")\n",
    "\n",
    "# Transcribes the audio into text\n",
    "response = client.recognize(request=request)\n",
    "\n",
    "for result in response.results:\n",
    "    print(f\"Transcript: {result.alternatives[0].transcript}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcribe Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=ku-N-eS1lgM\"\n",
    "\n",
    "def main():\n",
    "  prompt = \"\"\"\n",
    "    Process the audio file and generate a detailed transcription.\n",
    "\n",
    "    Requirements:\n",
    "    1. Identify distinct speakers (e.g., Speaker 1, Speaker 2, or names if context allows).\n",
    "    2. Provide accurate timestamps for each segment (Format: MM:SS).\n",
    "    3. Detect the primary language of each segment.\n",
    "    4. If the segment is in a language different than English, also provide the English translation.\n",
    "    5. Identify the primary emotion of the speaker in this segment. You MUST choose exactly one of the following: Happy, Sad, Angry, Neutral.\n",
    "    6. Provide a brief summary of the entire audio at the beginning.\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "      types.Content(\n",
    "        parts=[\n",
    "          types.Part(\n",
    "            file_data=types.FileData(\n",
    "              file_uri=YOUTUBE_URL\n",
    "            )\n",
    "          ),\n",
    "          types.Part(\n",
    "            text=prompt\n",
    "          )\n",
    "        ]\n",
    "      )\n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_mime_type=\"application/json\",\n",
    "      response_schema=types.Schema(\n",
    "        type=types.Type.OBJECT,\n",
    "        properties={\n",
    "          \"summary\": types.Schema(\n",
    "            type=types.Type.STRING,\n",
    "            description=\"A concise summary of the audio content.\",\n",
    "          ),\n",
    "          \"segments\": types.Schema(\n",
    "            type=types.Type.ARRAY,\n",
    "            description=\"List of transcribed segments with speaker and timestamp.\",\n",
    "            items=types.Schema(\n",
    "              type=types.Type.OBJECT,\n",
    "              properties={\n",
    "                \"speaker\": types.Schema(type=types.Type.STRING),\n",
    "                \"timestamp\": types.Schema(type=types.Type.STRING),\n",
    "                \"content\": types.Schema(type=types.Type.STRING),\n",
    "                \"language\": types.Schema(type=types.Type.STRING),\n",
    "                \"language_code\": types.Schema(type=types.Type.STRING),\n",
    "                \"translation\": types.Schema(type=types.Type.STRING),\n",
    "                \"emotion\": types.Schema(\n",
    "                  type=types.Type.STRING,\n",
    "                  enum=[\"happy\", \"sad\", \"angry\", \"neutral\"]\n",
    "                ),\n",
    "              },\n",
    "              required=[\"speaker\", \"timestamp\", \"content\", \"language\", \"language_code\", \"emotion\"],\n",
    "            ),\n",
    "          ),\n",
    "        },\n",
    "        required=[\"summary\", \"segments\"],\n",
    "      ),\n",
    "    ),\n",
    "  )\n",
    "\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TTS Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Synthesizes speech from the input string of text or ssml.\n",
    "Make sure to be working in a virtual environment.\n",
    "\n",
    "Note: ssml must be well-formed according to:\n",
    "    https://www.w3.org/TR/speech-synthesis/\n",
    "\"\"\"\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "# Instantiates a client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Set the text input to be synthesized\n",
    "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, World!\")\n",
    "\n",
    "# Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "# voice gender (\"neutral\")\n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    ")\n",
    "\n",
    "# Select the type of audio file you want returned\n",
    "audio_config = texttospeech.AudioConfig(\n",
    "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
    ")\n",
    "\n",
    "# Perform the text-to-speech request on the text input with the selected\n",
    "# voice parameters and audio file type\n",
    "response = client.synthesize_speech(\n",
    "    input=synthesis_input, voice=voice, audio_config=audio_config\n",
    ")\n",
    "\n",
    "# The response's audio_content is binary.\n",
    "with open(\"output.mp3\", \"wb\") as out:\n",
    "    # Write the response to the output file.\n",
    "    out.write(response.audio_content)\n",
    "    print('Audio content written to file \"output.mp3\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import EmbedContentConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = genai.Client()\n",
    "response = client.models.embed_content(\n",
    "    model=\"gemini-embedding-001\",\n",
    "    contents=[\n",
    "        \"How do I get a driver's license/learner's permit?\",\n",
    "        \"How long is my driver's license valid for?\",\n",
    "        \"Driver's knowledge test study guide\",\n",
    "    ],\n",
    "    config=EmbedContentConfig(\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\",  # Optional\n",
    "        output_dimensionality=3072,  # Optional\n",
    "        title=\"Driver's License\",  # Optional\n",
    "    ),\n",
    ")\n",
    "print(response)\n",
    "# Example response:\n",
    "# embeddings=[ContentEmbedding(values=[-0.06302902102470398, 0.00928034819662571, 0.014716853387653828, -0.028747491538524628, ... ],\n",
    "# statistics=ContentEmbeddingStatistics(truncated=False, token_count=13.0))]\n",
    "# metadata=EmbedContentMetadata(billable_character_count=112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "grounding_tool = types.Tool(\n",
    "    google_search=types.GoogleSearch()\n",
    ")\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[grounding_tool]\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Who won the euro 2024?\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"candidates\": [\n",
    "      {\n",
    "        \"content\": {\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": \"Spain won Euro 2024, defeating England 2-1 in the final. This victory marks Spain's record fourth European Championship title.\"\n",
    "            }\n",
    "          ],\n",
    "          \"role\": \"model\"\n",
    "        },\n",
    "        \"groundingMetadata\": {\n",
    "          \"webSearchQueries\": [\n",
    "            \"UEFA Euro 2024 winner\",\n",
    "            \"who won euro 2024\"\n",
    "          ],\n",
    "          \"searchEntryPoint\": {\n",
    "            \"renderedContent\": \"<!-- HTML and CSS for the search widget -->\"\n",
    "          },\n",
    "          \"groundingChunks\": [\n",
    "            {\"web\": {\"uri\": \"https://vertexaisearch.cloud.google.com.....\", \"title\": \"aljazeera.com\"}},\n",
    "            {\"web\": {\"uri\": \"https://vertexaisearch.cloud.google.com.....\", \"title\": \"uefa.com\"}}\n",
    "          ],\n",
    "          \"groundingSupports\": [\n",
    "            {\n",
    "              \"segment\": {\"startIndex\": 0, \"endIndex\": 85, \"text\": \"Spain won Euro 2024, defeatin...\"},\n",
    "              \"groundingChunkIndices\": [0]\n",
    "            },\n",
    "            {\n",
    "              \"segment\": {\"startIndex\": 86, \"endIndex\": 210, \"text\": \"This victory marks Spain's...\"},\n",
    "              \"groundingChunkIndices\": [0, 1]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_citations(response):\n",
    "    text = response.text\n",
    "    supports = response.candidates[0].grounding_metadata.grounding_supports\n",
    "    chunks = response.candidates[0].grounding_metadata.grounding_chunks\n",
    "\n",
    "    # Sort supports by end_index in descending order to avoid shifting issues when inserting.\n",
    "    sorted_supports = sorted(supports, key=lambda s: s.segment.end_index, reverse=True)\n",
    "\n",
    "    for support in sorted_supports:\n",
    "        end_index = support.segment.end_index\n",
    "        if support.grounding_chunk_indices:\n",
    "            # Create citation string like [1](link1)[2](link2)\n",
    "            citation_links = []\n",
    "            for i in support.grounding_chunk_indices:\n",
    "                if i < len(chunks):\n",
    "                    uri = chunks[i].web.uri\n",
    "                    citation_links.append(f\"[{i + 1}]({uri})\")\n",
    "\n",
    "            citation_string = \", \".join(citation_links)\n",
    "            text = text[:end_index] + citation_string + text[end_index:]\n",
    "\n",
    "    return text\n",
    "\n",
    "# Assuming response with grounding metadata\n",
    "text_with_citations = add_citations(response)\n",
    "print(text_with_citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \"What are the best Italian restaurants within a 15-minute walk from here?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        # Turn on grounding with Google Maps\n",
    "        tools=[types.Tool(google_maps=types.GoogleMaps())],\n",
    "        # Optionally provide the relevant location context (this is in Los Angeles)\n",
    "        tool_config=types.ToolConfig(retrieval_config=types.RetrievalConfig(\n",
    "            lat_lng=types.LatLng(\n",
    "                latitude=34.050481, longitude=-118.248526))),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\")\n",
    "print(response.text)\n",
    "\n",
    "if grounding := response.candidates[0].grounding_metadata:\n",
    "  if grounding.grounding_chunks:\n",
    "    print('-' * 40)\n",
    "    print(\"Sources:\")\n",
    "    for chunk in grounding.grounding_chunks:\n",
    "      print(f'- [{chunk.maps.title}]({chunk.maps.uri})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \"Is there a cafe near the corner of 1st and Main that has outdoor seating?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        # Turn on the Maps tool\n",
    "        tools=[types.Tool(google_maps=types.GoogleMaps())],\n",
    "\n",
    "        # Provide the relevant location context (this is in Los Angeles)\n",
    "        tool_config=types.ToolConfig(retrieval_config=types.RetrievalConfig(\n",
    "            lat_lng=types.LatLng(\n",
    "                latitude=34.050481, longitude=-118.248526))),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\")\n",
    "print(response.text)\n",
    "\n",
    "if grounding := response.candidates[0].grounding_metadata:\n",
    "  if chunks := grounding.grounding_chunks:\n",
    "    print('-' * 40)\n",
    "    print(\"Sources:\")\n",
    "    for chunk in chunks:\n",
    "      print(f'- [{chunk.maps.title}]({chunk.maps.uri})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "prompt = \"Which family-friendly restaurants near here have the best playground reviews?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "      tools=[types.Tool(google_maps=types.GoogleMaps())],\n",
    "      tool_config=types.ToolConfig(retrieval_config=types.RetrievalConfig(\n",
    "          # Provide the location as context; this is Austin, TX.\n",
    "          lat_lng=types.LatLng(\n",
    "              latitude=30.2672, longitude=-97.7431))),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\")\n",
    "print(response.text)\n",
    "\n",
    "if grounding := response.candidates[0].grounding_metadata:\n",
    "  if chunks := grounding.grounding_chunks:\n",
    "    print('-' * 40)\n",
    "    print(\"Sources:\")\n",
    "    for chunk in chunks:\n",
    "      print(f'- [{chunk.maps.title}]({chunk.maps.uri})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
